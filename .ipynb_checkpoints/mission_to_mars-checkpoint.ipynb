{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "news_url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "browser.visit(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "run = True\n",
    "while run:\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    news_items = soup.find('ul', class_='item_list')\n",
    "\n",
    "    news_categories = news_items.find_all('div', class_=\"list_text\")\n",
    "\n",
    "    news_title_list=[]\n",
    "    paragraph_list=[]\n",
    "    for news_category in news_categories:\n",
    "        try:\n",
    "            news_title = news_category.find('div', class_='content_title').text\n",
    "            news_title_list.append(news_title)\n",
    "            paragraph = news_category.find('div', class_='article_teaser_body').text\n",
    "            paragraph_list.append(paragraph)\n",
    "            print('-----------')\n",
    "            print(f\"News Title:{news_title}\")\n",
    "            print(paragraph)\n",
    "\n",
    "            news_title_and_paragraph = zip(news_title_list, paragraph_list)\n",
    "        \n",
    "        except Except as e:\n",
    "            print(f\"error: {news_category}\")\n",
    "\n",
    "    try:\n",
    "        browser.click_link_by_partial_text('More')\n",
    "\n",
    "    except:\n",
    "        run= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_items = soup.find('ul', class_='item_list')\n",
    "\n",
    "#news_categories = news_items.find_all('div', class_=\"list_text\")\n",
    "\n",
    "#news_title_list=[]\n",
    "#paragraph_list=[]\n",
    "#for news_category in news_categories:\n",
    "    #news_title = news_category.find('div', class_='content_title').text\n",
    "    #news_title_list.append(news_title)\n",
    "    #paragraph = news_category.find('div', class_='article_teaser_body').text\n",
    "    #paragraph_list.append(paragraph)\n",
    "    #print('-----------')\n",
    "    #print(f\"News Title:{news_title}\")\n",
    "    #print(paragraph)\n",
    "    \n",
    "    #news_title_and_paragraph = zip(news_title_list, paragraph_list)\n",
    "\n",
    "#try:\n",
    "    #for result in news_title_and_paragraph:\n",
    "        \n",
    "        #browser.click_link_by_partial_text('More')\n",
    "          \n",
    "#except:\n",
    "    #print(\"Scraping Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars Now : \n",
      "Like much of the rest of the world, the Mars rover team is pushing forward with its mission-critical work while putting the health and safety of their colleagues and community first.\n"
     ]
    }
   ],
   "source": [
    "#news_categories = soup.find_all('div', class_=\"list_text\")\n",
    "\n",
    "news_title = soup.find('div', class_='content_title').text\n",
    "news_p = soup.find('div', class_='article_teaser_body').text\n",
    "print(f'{news_title} : \\n{news_p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "main_url='https://www.jpl.nasa.gov'\n",
    "img_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(img_url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spaceimages/images/wallpaper/PIA19673-1920x1200.jpg\n",
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA19673-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "# For using as a backround image\n",
    "main_image_items = soup.find('article', class_=\"carousel_item\")\n",
    "main_image= main_image_items['style'].split(\"'\")[1]\n",
    "main_image_url=main_url + main_image\n",
    "print(main_image)\n",
    "print(main_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spaceimages/images/wallpaper/PIA23844-640x350.jpg\n",
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA23844-640x350.jpg\n"
     ]
    }
   ],
   "source": [
    "feature_image_items = soup.find('li', class_=\"slide\")\n",
    "feature_image = feature_image_items.find(\"img\", class_=\"thumb\")[\"src\"]\n",
    "feature_image_url = main_url + feature_image\n",
    "\n",
    "print(feature_image)\n",
    "print(feature_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "weather_url='https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(weather_url)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_items=soup.find_all(\"span\", class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\")\n",
    "#print(tweet_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(tweet_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars Weather\n"
     ]
    }
   ],
   "source": [
    "mars_weather=soup.find_all(\"span\", class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\")[27].text\n",
    "\n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InSight sol 503 (2020-04-26) low -93.8ºC (-136.8ºF) high -4.9ºC (23.2ºF)\n",
      "winds from the WNW at 4.6 m/s (10.2 mph) gusting to 17.5 m/s (39.1 mph)\n",
      "pressure at 6.70 hPa\n"
     ]
    }
   ],
   "source": [
    "def contains_word(t):\n",
    "    return t and 'InSight' in t\n",
    "\n",
    "tweet = soup.find_all('span', text=contains_word)[0].text\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "fact_url = \"http://space-facts.com/mars/\"\n",
    "browser.visit(fact_url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_tables = pd.read_html(fact_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fact_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mars - Earth Comparison</th>\n",
       "      <th>Mars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diameter:</td>\n",
       "      <td>6,779 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Distance from Sun:</td>\n",
       "      <td>227,943,824 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Year:</td>\n",
       "      <td>687 Earth days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Temperature:</td>\n",
       "      <td>-153 to 20 °C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Mars - Earth Comparison             Mars\n",
       "0               Diameter:         6,779 km\n",
       "1                   Mass:  6.39 × 10^23 kg\n",
       "2                  Moons:                2\n",
       "3      Distance from Sun:   227,943,824 km\n",
       "4         Length of Year:   687 Earth days\n",
       "5            Temperature:    -153 to 20 °C"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=fact_tables[1]\n",
    "\n",
    "df1=df.drop([\"Earth\"], axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>Mars - Earth Comparison</th>\\n      <th>Mars</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>Diameter:</td>\\n      <td>6,779 km</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.39 × 10^23 kg</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <td>Distance from Sun:</td>\\n      <td>227,943,824 km</td>\\n    </tr>\\n    <tr>\\n      <td>Length of Year:</td>\\n      <td>687 Earth days</td>\\n    </tr>\\n    <tr>\\n      <td>Temperature:</td>\\n      <td>-153 to 20 °C</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_table = df1.to_html(index=False)\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th>Mars - Earth Comparison</th>      <th>Mars</th>    </tr>  </thead>  <tbody>    <tr>      <td>Diameter:</td>      <td>6,779 km</td>    </tr>    <tr>      <td>Mass:</td>      <td>6.39 × 10^23 kg</td>    </tr>    <tr>      <td>Moons:</td>      <td>2</td>    </tr>    <tr>      <td>Distance from Sun:</td>      <td>227,943,824 km</td>    </tr>    <tr>      <td>Length of Year:</td>      <td>687 Earth days</td>    </tr>    <tr>      <td>Temperature:</td>      <td>-153 to 20 °C</td>    </tr>  </tbody></table>'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Strip unwanted newlines to clean up the table.\n",
    "mars_table=html_table.replace('\\n', '')\n",
    "mars_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the table directly to a file.\n",
    "df1.to_html('static/html_table.html', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file in the browser\n",
    "#!open mars_table.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "hemi_main_url='https://astrogeology.usgs.gov'\n",
    "hemisphere_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(hemisphere_url)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}]\n",
      "[{'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}, {'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}]\n",
      "[{'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}, {'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}, {'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}]\n",
      "[{'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}, {'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}, {'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}, {'hemi_title': 'Valles Marineris', 'link': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}]\n"
     ]
    }
   ],
   "source": [
    "hemispheres = []\n",
    "\n",
    "results = soup.find_all(\"div\", class_=\"item\")\n",
    "\n",
    "for result in results:\n",
    "    hemi_title = result.find(\"h3\").text\n",
    "    hemi_link = result.find('a')\n",
    "    hemi_href = link['href']\n",
    "    hemispheres.append({\"hemi_title\": title, \"hemi_img\": hemi_link,  \"link\":(hemi_main_url + hemi_href)})\n",
    "\n",
    "    hemis_results = list(np.ravel(hemispheres))\n",
    "    \n",
    "    print(hemis_results)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cerberus Hemisphere Enhanced'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemis_results[0]['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemis_results[0]['img_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-306d6aaf0611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhemi_titles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick_link_by_partial_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhemi_image_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"downloads\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhemi_image_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "hemi_titles = [\"Cerberus\",\"Schiaparelli\",\"Syrtis Major\",\"Valles Marineris\"]\n",
    "hemi_image_url = []\n",
    "for title in hemi_titles:\n",
    "    browser.click_link_by_partial_text(title)\n",
    "    hemi_image_url.append(soup.find_all(\"div\", class_=\"downloads\")[0].find_all(\"a\")[0][\"href\"])\n",
    "    print(hemi_image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Cerberus\n",
      "error: Schiaparelli\n",
      "error: Syrtis Major\n",
      "error: Valles Marineris\n"
     ]
    }
   ],
   "source": [
    "hemi_titles = [\"Cerberus\",\"Schiaparelli\",\"Syrtis Major\",\"Valles Marineris\"]\n",
    "hemi_image_url = []\n",
    "for title in hemi_titles:\n",
    "    try:\n",
    "        browser.click_link_by_partial_text(title)\n",
    "        hemi_image_url.append(soup.find_all(\"div\", class_=\"downloads\")[0].find_all(\"a\")[0][\"href\"])\n",
    "        print(title)\n",
    "        print(hemi_image_url)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"error: {title}\")\n",
    "\n",
    "    try:\n",
    "        browser.click_link_by_partial_text(title)\n",
    "\n",
    "    except:\n",
    "        run= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-454b978d75d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhemi_image_url\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "hemi_image_url[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementDoesNotExist",
     "evalue": "no elements could be found with link by partial text \"Cerberus\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/splinter/element_list.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mElementDoesNotExist\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-f02a5cb85633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhemi_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick_link_by_partial_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/splinter/driver/__init__.py\u001b[0m in \u001b[0;36mclick_link_by_partial_text\u001b[0;34m(self, partial_text)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mClicks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlink\u001b[0m \u001b[0mby\u001b[0m \u001b[0mpartial\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0mof\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \"\"\"\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_link_by_partial_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclick_link_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/splinter/element_list.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0melement_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melement_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/splinter/element_list.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     44\u001b[0m             raise ElementDoesNotExist(\n\u001b[1;32m     45\u001b[0m                 u'no elements could be found with {0} \"{1}\"'.format(\n\u001b[0;32m---> 46\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 )\n\u001b[1;32m     48\u001b[0m             )\n",
      "\u001b[0;31mElementDoesNotExist\u001b[0m: no elements could be found with link by partial text \"Cerberus\""
     ]
    }
   ],
   "source": [
    "titles = [\"Cerberus\",\"Schiaparelli\",\"Syrtis Major\",\"Valles Marineris\"]\n",
    "hemi_img = []\n",
    "for tit in titles:\n",
    "    browser.click_link_by_partial_text(tit)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    hemi_img.append(soup.find_all(\"div\", class_=\"downloads\")[0].find_all(\"a\")[0][\"href\"])\n",
    "    browser.back()\n",
    "\n",
    "print(hemi_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
