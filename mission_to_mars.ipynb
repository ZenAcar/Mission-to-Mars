{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup \n",
    "import pymongo\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "news_url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "browser.visit(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "run = True\n",
    "while run:\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    news_items = soup.find('ul', class_='item_list')\n",
    "\n",
    "    news_categories = news_items.find_all('div', class_=\"list_text\")\n",
    "\n",
    "    news_title_list=[]\n",
    "    paragraph_list=[]\n",
    "    for news_category in news_categories:\n",
    "        try:\n",
    "            news_title = news_category.find('div', class_='content_title').text\n",
    "            news_title_list.append(news_title)\n",
    "            paragraph = news_category.find('div', class_='article_teaser_body').text\n",
    "            paragraph_list.append(paragraph)\n",
    "            print('-----------')\n",
    "            print(f\"News Title:{news_title}\")\n",
    "            print(paragraph)\n",
    "\n",
    "            news_title_and_paragraph = zip(news_title_list, paragraph_list)\n",
    "        \n",
    "        except Except as e:\n",
    "            print(f\"error: {news_category}\")\n",
    "\n",
    "    try:\n",
    "        browser.click_link_by_partial_text('More')\n",
    "\n",
    "    except:\n",
    "        run= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_items = soup.find('ul', class_='item_list')\n",
    "\n",
    "#news_categories = news_items.find_all('div', class_=\"list_text\")\n",
    "\n",
    "#news_title_list=[]\n",
    "#paragraph_list=[]\n",
    "#for news_category in news_categories:\n",
    "    #news_title = news_category.find('div', class_='content_title').text\n",
    "    #news_title_list.append(news_title)\n",
    "    #paragraph = news_category.find('div', class_='article_teaser_body').text\n",
    "    #paragraph_list.append(paragraph)\n",
    "    #print('-----------')\n",
    "    #print(f\"News Title:{news_title}\")\n",
    "    #print(paragraph)\n",
    "    \n",
    "    #news_title_and_paragraph = zip(news_title_list, paragraph_list)\n",
    "\n",
    "#try:\n",
    "    #for result in news_title_and_paragraph:\n",
    "        \n",
    "        #browser.click_link_by_partial_text('More')\n",
    "          \n",
    "#except:\n",
    "    #print(\"Scraping Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars Now : \n",
      "As a longtime fan of space exploration, Vaneeza Rupani appreciates the creativity and collaboration involved with trying to fly on another planet.\n"
     ]
    }
   ],
   "source": [
    "#news_categories = soup.find_all('div', class_=\"list_text\")\n",
    "\n",
    "news_title = soup.find('div', class_='content_title').text\n",
    "news_p = soup.find('div', class_='article_teaser_body').text\n",
    "print(f'{news_title} : \\n{news_p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "main_url='https://www.jpl.nasa.gov'\n",
    "img_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(img_url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spaceimages/images/wallpaper/PIA18906-1920x1200.jpg\n",
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA18906-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "# For using as a backround image\n",
    "main_image_items = soup.find('article', class_=\"carousel_item\")\n",
    "main_image= main_image_items['style'].split(\"'\")[1]\n",
    "main_image_url=main_url + main_image\n",
    "print(main_image)\n",
    "print(main_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spaceimages/images/wallpaper/PIA23857-640x350.jpg\n",
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA23857-640x350.jpg\n"
     ]
    }
   ],
   "source": [
    "feature_image_items = soup.find('li', class_=\"slide\")\n",
    "feature_image = feature_image_items.find(\"img\", class_=\"thumb\")[\"src\"]\n",
    "feature_image_url = main_url + feature_image\n",
    "\n",
    "print(feature_image)\n",
    "print(feature_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "weather_url='https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(weather_url)\n",
    "time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-518620b749e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmars_weather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmars_weather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "mars_weather = soup.find('article').find_all('span')[4].text\n",
    "\n",
    "print(mars_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_items=soup.find_all(\"span\", class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\")\n",
    "#print(tweet_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(tweet_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-ed2271f42f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmars_weather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmars_weather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mars_weather=soup.find_all(\"span\", class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\")[27].text\n",
    "\n",
    "print(mars_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-27aac87afeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'InSight'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontains_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def contains_word(t):\n",
    "    return t and 'InSight' in t\n",
    "\n",
    "tweet = soup.find_all('span', text=contains_word)[0].text\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "fact_url = \"http://space-facts.com/mars/\"\n",
    "browser.visit(fact_url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_tables = pd.read_html(fact_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fact_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mars - Earth Comparison</th>\n",
       "      <th>Mars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diameter:</td>\n",
       "      <td>6,779 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Distance from Sun:</td>\n",
       "      <td>227,943,824 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Year:</td>\n",
       "      <td>687 Earth days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Temperature:</td>\n",
       "      <td>-153 to 20 °C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Mars - Earth Comparison             Mars\n",
       "0               Diameter:         6,779 km\n",
       "1                   Mass:  6.39 × 10^23 kg\n",
       "2                  Moons:                2\n",
       "3      Distance from Sun:   227,943,824 km\n",
       "4         Length of Year:   687 Earth days\n",
       "5            Temperature:    -153 to 20 °C"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=fact_tables[1]\n",
    "df1=df.drop([\"Earth\"], axis=1)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th>Mars - Earth Comparison</th>      <th>Mars</th>    </tr>  </thead>  <tbody>    <tr>      <td>Diameter:</td>      <td>6,779 km</td>    </tr>    <tr>      <td>Mass:</td>      <td>6.39 × 10^23 kg</td>    </tr>    <tr>      <td>Moons:</td>      <td>2</td>    </tr>    <tr>      <td>Distance from Sun:</td>      <td>227,943,824 km</td>    </tr>    <tr>      <td>Length of Year:</td>      <td>687 Earth days</td>    </tr>    <tr>      <td>Temperature:</td>      <td>-153 to 20 °C</td>    </tr>  </tbody></table>\n"
     ]
    }
   ],
   "source": [
    "html_table = df1.to_html(index=False)\n",
    "html_table=html_table.replace('\\n', '')\n",
    "print(html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the table directly to a file.\n",
    "df1.to_html('static/html_table.html', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file in the browser\n",
    "#!open mars_table.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "hemi_main_url='https://astrogeology.usgs.gov'\n",
    "hemispheres_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(hemispheres_url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "hemispheres_items = soup.find_all('div', class_='item')\n",
    "\n",
    "hemisphere_data = []\n",
    "\n",
    "for hemisphere in  hemispheres_items:\n",
    "    # Titles\n",
    "    hemisphere = hemisphere.find('div', class_=\"description\")\n",
    "    title = hemisphere.h3.text\n",
    "    # Links\n",
    "    hemi_href = hemisphere.a[\"href\"] \n",
    "    browser.visit(hemi_main_url + hemi_href)\n",
    "    time.sleep(2)\n",
    "\n",
    "    image_html = browser.html\n",
    "    image_soup = BeautifulSoup(image_html, 'html.parser')\n",
    "\n",
    "    img_items = image_soup.find('div', class_='downloads')\n",
    "    img_url = img_items.find('li').a['href']\n",
    "    \n",
    "    # Dictionary\n",
    "    hemisphere_data.append({\"title\": title, \"img_url\": img_url})\n",
    "    \n",
    "print(hemisphere_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "hemispheres = []\n",
    "results = soup.find_all(\"div\", class_=\"item\")\n",
    "\n",
    "for result in results:\n",
    "    title = result.find(\"h3\").text\n",
    "    link = result.find('a')\n",
    "    href = link['href']\n",
    "    src= link.find(\"img\")[\"src\"]\n",
    "    \n",
    "    hemi_title=hemispheres\n",
    "   \n",
    "    hemispheres.append({\"hemi_title\": title, \"hemi_src\":(hemi_main_url+src) ,\"hemi_link\":(hemi_main_url + href)})\n",
    "\n",
    "    hemi_results = list(np.ravel(hemispheres))\n",
    "    \n",
    "    print(hemi_results)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hemi_titles = [\"Cerberus\",\"Schiaparelli\",\"Syrtis Major\",\"Valles Marineris\"]\n",
    "hemi_image_url = []\n",
    "for title in hemi_titles:\n",
    "    try:\n",
    "        browser.click_link_by_partial_text(title)\n",
    "        hemi_image_url.append(soup.find_all(\"div\", class_=\"downloads\")[0].find_all(\"a\")[0][\"href\"])\n",
    "        print(title)\n",
    "        print(hemi_image_url)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"error: {title}\")\n",
    "\n",
    "    try:\n",
    "        browser.click_link_by_partial_text(title)\n",
    "        time.sleep(5)\n",
    "\n",
    "    except:\n",
    "        run= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
